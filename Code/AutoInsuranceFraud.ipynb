{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection\n",
    "\n",
    "This notebook shows how to use Amazon Sagemaker Processsing, Data Wrangler and Amazon Glue Data Brew to prepare the data. \n",
    "\n",
    "First, we process the raw dataset to prepare the features and extract the interactions in the dataset that will be used to construct the graph. \n",
    "\n",
    "Then, we create a launch a training job using the SageMaker framework estimator to train a XGBoost model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Initial Setup\n",
    "\n",
    "The below code is used to get the S3 Bucket name configured for Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[31mERROR: File \"setup.py\" or \"setup.cfg\" not found. Directory cannot be installed in editable mode: /root/AutoInsuranceFraudDetection/Code/sagemaker_graph_fraud_detection\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "S3 bucket name:  sagemaker-us-east-1-367858208265\n"
     ]
    }
   ],
   "source": [
    "!bash setup.sh\n",
    "! pip install -qU sagemaker\n",
    "import sagemaker\n",
    "from sagemaker_graph_fraud_detection import config\n",
    "\n",
    "role = config.role\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()  \n",
    "print(\"S3 bucket name: \", bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Sagemaker Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#container to run the processing. The ecr_repository_uri will vary depending on the region. The \"source\" field is used for the dataset and the \"destination\" is used to store the prepared data\n",
    "ecr_repository_uri = \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\"\n",
    "source = 's3://'+bucket+'/AutoInsuranceFraudDetection/DataSet/insurance_claims.csv'\n",
    "destination = 's3://'+bucket+'/AutoInsuranceFraudDetection/Results/DataProcessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting AutoInsuranceFraudProcessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile AutoInsuranceFraudProcessing.py\n",
    "#This block of code generates a file \"AutoInsuranceFraudProcessing.py\" which has the code to process the data\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer, KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #get arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args, _ = parser.parse_known_args()\n",
    "    print(\"Received arguments {}\".format(args))\n",
    "    \n",
    "    #get the input data\n",
    "    input_data_path = os.path.join(\"/opt/ml/processing/input\", \"insurance_claims.csv\")\n",
    "    print(\"Reading input data from {}\".format(input_data_path))\n",
    "    df = pd.read_csv(input_data_path)\n",
    "    df = pd.DataFrame(data=df)\n",
    "    print(df.head())\n",
    "\n",
    "    #replacing ? with nan for the columns\n",
    "    df['police_report_available']=df['police_report_available'].replace('?',np.nan)\n",
    "    #dropping the unnecessary rows\n",
    "    df=df.dropna(subset=['police_report_available'])\n",
    "    \n",
    "    #drop unnecessary columns\n",
    "    df=df.drop(['months_as_customer'],axis=1)\n",
    "    \n",
    "    #now deal with the categorical features\n",
    "    #for the columns insured_sex and fraud_reported\n",
    "    le=LabelEncoder()\n",
    "    for i in list(df.columns):\n",
    "        if df[i].dtype=='object':\n",
    "            df[i]=le.fit_transform(df[i])\n",
    "    \n",
    "    #final preprocessed data\n",
    "    print(df.head())\n",
    "    train_features_output_path = os.path.join(\"/opt/ml/processing/output\", \"preprocessed_data.csv\")\n",
    "    df.to_csv(train_features_output_path, index=False)\n",
    "    print(\"done\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Preprocessing job with Amazon SageMaker Processing\n",
    "\n",
    "The script we have defined at `AutoInsuranceFraudProcessing.py` performs data preprocessing transformations on the raw data. The preproceesing involes replacing values, droping rows, dropping columns and categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2021-09-14-08-16-30-423\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-367858208265/AutoInsuranceFraudDetection/DataSet/insurance_claims.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-367858208265/sagemaker-scikit-learn-2021-09-14-08-16-30-423/input/code/AutoInsuranceFraudProcessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'preprocessed_data.csv', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-367858208265/AutoInsuranceFraudDetection/Results/DataProcessing', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "............................\u001b[34mReceived arguments Namespace()\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/processing/input/insurance_claims.csv\n",
      "   Unnamed: 0  months_as_customer  age  ...  vehicle_claim  auto_make  fraud_reported\u001b[0m\n",
      "\u001b[34m0           0                 328   48  ...          52080         10               Y\u001b[0m\n",
      "\u001b[34m1           1                 228   42  ...           3510          8               Y\u001b[0m\n",
      "\u001b[34m2           2                 134   29  ...          23100          4               N\u001b[0m\n",
      "\u001b[34m3           3                 256   41  ...          50720          3               Y\u001b[0m\n",
      "\u001b[34m4           4                 228   44  ...           4550          0               N\n",
      "\u001b[0m\n",
      "\u001b[34m[5 rows x 31 columns]\n",
      "   Unnamed: 0  age  policy_number  ...  vehicle_claim  auto_make  fraud_reported\u001b[0m\n",
      "\u001b[34m0           0   48         521585  ...          52080         10               1\u001b[0m\n",
      "\u001b[34m2           2   29         687698  ...          23100          4               0\u001b[0m\n",
      "\u001b[34m3           3   41         227811  ...          50720          3               1\u001b[0m\n",
      "\u001b[34m4           4   44         367455  ...           4550          0               0\u001b[0m\n",
      "\u001b[34m5           5   39         104594  ...          51280         10               1\n",
      "\u001b[0m\n",
      "\u001b[34m[5 rows x 30 columns]\u001b[0m\n",
      "\u001b[34mdone\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor = ScriptProcessor(command=['python3'],\n",
    "                                   image_uri=ecr_repository_uri,\n",
    "                                   role=role,\n",
    "                                   instance_count=1,\n",
    "                                   instance_type='ml.m4.2xlarge')\n",
    "\n",
    "script_processor.run(code='AutoInsuranceFraudProcessing.py',\n",
    "                     inputs=[ProcessingInput(source=source,\n",
    "                                             destination='/opt/ml/processing/input')],\n",
    "                     outputs=[ProcessingOutput(output_name=\"preprocessed_data.csv\", destination=destination,\n",
    "                                               source='/opt/ml/processing/output')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Results of Data Preprocessing\n",
    "\n",
    "Once the preprocessing job is complete, we can take a look at the contents of the S3 bucket to see the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OutputName': 'preprocessed_data.csv', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-367858208265/AutoInsuranceFraudDetection/Results/DataProcessing', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}\n",
      "s3://sagemaker-us-east-1-367858208265/AutoInsuranceFraudDetection/Results/DataProcessing\n"
     ]
    }
   ],
   "source": [
    "preprocessing_job_description = script_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    print(output)\n",
    "    preprocessed_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "    print(preprocessed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is completed, the training instances are automatically saved and SageMaker stores the trained model and evaluation results to a location in S3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
